{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and  Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement mediapipe (from versions: none)\n",
      "ERROR: No matching distribution found for mediapipe\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_pose = mp. solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = 'lean.avi'\n",
    "EXPORT_PATH = 'lean. osv'\n",
    "MODEL_PATH  =  'lean. pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1XSave Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2. VideoCapture(3)\n",
    "\n",
    "\n",
    "height = cap.get (cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width =  cap•get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get (cv2.CAP_PROP_FPS)\n",
    "videoWriter = cv2.VideoWriter (VIDEO_PATH, cv2.VideoWriter_fourcc('P', 'I', 'M', '1'), fps, (int(width), int(height)))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "       cv2. imshow('Press', frame)\n",
    "       videoWriter. write(frame)\n",
    "    except Exception as e:\n",
    "        break\n",
    "    if cv2.waitKey (10) & OxFF== ord('9'):\n",
    "        break\n",
    "\n",
    "cap. release()\n",
    "videoWriter.release()\n",
    "cv2. destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Capture Landmarks and export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x({})'.format(val), 'y({})'.format(val), 'z({})'.format(val), 'v({})'.format(val)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_PATH, mode ='w', newline='') as f:\n",
    "\n",
    "  csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting =csv. QUOTE_ MINIMAL)\n",
    "  csv_writer.writerow(landmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmark(results, action):\n",
    " try:\n",
    "    keypoints =np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() \n",
    "    keypoints.insert(0,action)\n",
    "    with open(EXPORT_PATH,mode='a',newline='') as f:\n",
    "         csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting =csv. QUOTE_ MINIMAL)\n",
    "         csv_writer.writerow(keypoints)\n",
    " except Exception as e:\n",
    "    pass       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(FILE_NAME)\n",
    "    # Initiate holistic model\n",
    "with mp_pose.Pose(min_detection_confidence =0.5,min_tracking_confidence =0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor (frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # Make Detections\n",
    "        results = pose.process(image)\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags .writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing. draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius =2)\n",
    "                                 )\n",
    "        k =cv2. waitkey(1) \n",
    "        if k== ord('a'):\n",
    "            export_landmark(results, 'wide')\n",
    "        if k==ord('s'):\n",
    "            export_landmark(results, 'neutral')\n",
    "        if k==ord('d'):\n",
    "            export_landmark(results, 'narrow') \n",
    "\n",
    "\n",
    "        cv2. imshow( 'Raw Webcam Feed', image) \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "           break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/venka/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Train Customm Model Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('class',axis=1)#feautures\n",
    "y=df['class']  #target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3,\n",
    "random_state =1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Train Macjhine Learning Classification Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "import  sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'rf': make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines. items():\n",
    "    model = pipeline. fit(X_train, y_train)\n",
    "    fit_models[algo]=model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Evaluate and Serialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score # Accuracy metrics \n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model. predict(X_test)\n",
    "    print(algo, accuracy_score(y_test.values, yhat),\n",
    "    precision_score(y_test.values, yhat, average =\"weighted\"), \n",
    "    recall_score(y_test.values, yhat, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_PATH,'wb') as f:\n",
    "    pickle.dump(fit_models['rf'],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_PATH,'rb') as f:\n",
    "    model=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2. VideoCapture(0)\n",
    "counter = 0\n",
    "current_stage = ' '\n",
    "# Initiate holistic model\n",
    "with mp_pose. Pose(min_detection_confidence =0.5, min_tracking_confidence =0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "# Recolor Feed\n",
    "            image = cv2. cvtColor (frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "# Make Detections\n",
    "            results =pose.process (image)\n",
    "# Recolor image back to BR for rendering\n",
    "            image.flags.writeable = True\n",
    "            image = cv2. cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius =4), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness =2, circle_radius=2)\n",
    "                                     \n",
    "                                     )\n",
    "            try:\n",
    "                row = np.array([[res.x, res.y, res.z, res.visibility]  for res in results.pose_landmarks.landmark]).flatten()\n",
    "                X=pd.DataFrame([row],columns=landmarks[1:])\n",
    "                body_language_class=model.predict(X)[0]\n",
    "                body_language_prob=model.predict_proba(X)[0]\n",
    "                print(body_language_class,body_language_prob)\n",
    "                if (body_language_class =='left' and body_language_prob[body_language_prob.argmax()]>=.7 )| (body_language_class =='right' and body_language_prob[body_language_prob.argmax()]>=.7 )| (body_language_class =='neutral' and body_language_prob[body_language_prob.argmax()]>=.7 ):\n",
    "                     current_stage=body_language_class \n",
    "                elif current_stage != body_language_class  and body_language_prob[body_language_prob.argmax()]>=.7: \n",
    "                     current_stage=body_language_class\n",
    "                     \n",
    "                     print(current_stage)\n",
    "\n",
    "                #Get Status box\n",
    "                cv2.rectangle(image,(0,0),(250,60),(245,117,16),-1)\n",
    "                #display class\n",
    "                cv2.putText(image,'CLASS',(95,12),cv2.FONT_HARSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA) \n",
    "                cv2.putText(image,body_language_class.split(' ')[0],(90,40),cv2.FONT_HARSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)    \n",
    "                #Display probabilities\n",
    "                cv2.putText(image,'PROB',(15,12),cv2.FONT_HARSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "                cv2.putText(image,str(round(body_language_prob[np.argmax(body_language_prob)],2)),(10,40),cv2.FONT_HARSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            cv2.imshow(\"window\",image) \n",
    "             \n",
    "            if cv2.waitkey(10) & 0XFF== ord('q'):\n",
    "                 break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()            \n",
    " \n",
    "\n",
    "                       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
